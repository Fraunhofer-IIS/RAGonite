{
    "id": "confluence-150",
    "title": "Community Call - 15th December 2016",
    "url": "https://openxt.atlassian.net/wiki/spaces/CS/pages/70713346/Community+Call+-+15th+December+2016",
    "content": "<p>Owned by Christopher Clark\nLast updated: Dec 15, 2016 by Christopher Clark\n\n</p><p>Minutes by Christopher Clark. Copyright (c) 2016 BAE Systems.</p><p><br/></p><p>Present:</p><p>Christopher Clark, Rich Persaud; BAE</p><p>Jim Rauscher and R2</p><p>James McKenzie; Bromium</p><p>Daniel Smith; Apertus</p><p>Ross Philipson, Eric Chanudet; AIS Burlington</p><p>Kevin Pearson; AFRL</p><p><br/></p><h2>tboot and UEFI</h2><p>Ross: have had a request to formalize a plan</p><p>Kevin: requesting a RFC document for host UEFI integration to give others a chance to review the approach.</p><p>James: happy to write it</p><p><br/></p><p>Overview of the work:</p><p>SMX mode must be entered after performing exit boot services.</p><p><br/></p><p>Option 1: fold tboot into Xen</p><p>Option 2: if desirable to preserve the separation of the projects, compile tboot as a driver for UEFI.</p><p><br/></p><p>Advantage of Option 1:</p><p>Not all BIOSes will measure all modules into PCR4, so some hacking required to get those measurements;</p><p>have some code for TPM 2.0 and TrEE and also some for TPM 1, but this is not as nice as having the platform just do it for you.</p><p><br/></p><p>Ross: think the uefi module is the easier approach</p><p><br/></p><p>James: Then there's the handoff after SIPI to handle. Can avoid extra SIPI logic in tboot if linked into Xen.</p><p><br/></p><p><strong>ACTION: Ross to get together with James to discuss technical details (eg. PCR4 measurement issue)</strong></p><p><br/></p><p>Daniel: has anyone spoken to upstream?</p><p>James: tboot upstream is not very active.</p><p>Ross: concur; tboot project health looks bleak.</p><p><br/></p><p><strong>ACTION: Rich to talk to upstream Xen to understand whether Xen adoption may be viable and if so, what would be involved.</strong></p><p><br/></p><p>James: One barrier is that TPM 2.0 specs are very hard to obtain.</p><p>It is an ISO standard rather than a TCG standard, so an ISO subscription is required. Has been removed from the TCG web site.</p><p><br/></p><p>Rich: What's the driving hardware requirement behind TPM 2.0 support?</p><p>Kevin: Microsoft Surface. \"CSM\" going away next year or two. Surface Pro, ProBook, Surface Studio.</p><p><br/></p><p>Ross: With a Xen merge there are both technical and non-technical concerns; not known if wanted; licensing eg. FreeBSD code in tboot</p><p><br/></p><p>James: Should be simpler: In the new implementation, the platform measures rather than tboot code.</p><p><br/></p><p><strong>ACTION: Ross and James to write a doc so that Rich can start the upstream discussion.</strong></p><p><br/></p><p>James: the gist is: \"Support a module that goes into Xen binary that runs when Xen starts\".</p><p><br/></p><p><br/></p><h2>icbinn</h2><p>Software designed to support 2-3 syncxt VMs, managing a subset of the platform and the transfer of VHDs.</p><p><br/></p><p>James: Designed to run a filesystem over a stream.</p><p>Took SUN-RPC, glued it to a stream protocol, to libc functions.</p><p>Goal to be very simple, inspectable and not much code; to run in dom0 or a storage domain, expose POSIX calls remoted via SUN-XDR.</p><p>The difference between icbinn and icbinn_resolve is in the linking: icbinn_resolve is build as a static binary suitable for deployment on any foreign distro with no shared library dependencies.</p><p>The preexisting options at the time were NFS, CIFS, SMB; all are complicated. A kernel-side implementation has security implications: harder to apply Access Control and have special access to the kernel, including inode lookup functions. icbinn is just a usermode process, and so can be confined using standard mechanisms. Much smaller and more lightweight than CIFS.</p><p>There is also a pure python implementation, so it can run in a language with measured memory. The original Synchronizer VMs used it. Just import a python module and have access to it as a filesystem, with all existing python libraries.</p><p>icbinn would be usable outside of OpenXT, by anyone else. Provides a POSIX filesystem over a socket.</p><p><br/></p><p><strong>ACTION: Rich to document it to aid in presenting to other potential users.</strong></p><h2>Release targets for 7.0 and 7.1</h2><p>Rich: There is interest in a release before June for Kaby Lake support.</p><p>Kevin: Current target for a derivative release is at the end of March 2017.</p><p>Requirements: Kaby Lake, TPM 2.0 and host UEFI if ready.</p><p>Measured Launch should also be included. libxl would make things easier if in.</p><p><br/></p><p>Ross: libxl is not in yet but close, looking positive.</p><p><br/></p><p>Rich: Plan: 7.0 in March, potentially 7.1 in June.</p><p><br/></p><p>Ross: Eric is working on Linux 4.9 integration, which is the main part of Kaby Lake support.</p><p>Kevin: Intel have not released the SINIT ACM for Kaby Lake yet. Our org is doing TPM 2.0 work with meta-measured, and getting ready to post for OpenXT.</p><p>Need to get with AIS Rome for the measured launch part.</p><p><br/></p><p>Ross: May have to work with existing tboot to get TPM 2.0 for now.</p><p><br/></p><p>Rich: Request that this work is done in public with a RFC describing it. Daniel is the 7.0 release manager. Visibility is important.</p><p>Release planning for 7.0 will start in January.</p><p><br/></p><p>Christopher: Xen 4.6 is already in master and will be included in the release.</p><p>Ross: Yes, and qemu, libxl and Linux uprevs too. TPM 2.0 is an open question.</p><p><br/></p><p>Rich: Host UEFI for 7.0 release in March seems unlikely.</p><p>Ross: meta-measured versus OpenXT measured launch: work involved in integration is not known yet.</p><p>Need both TPM 1.0 and 2.0 support: so switch at install time or runtime?</p><p><br/></p><p>Kevin: Need to continue to support TPM 1.0 for existing systems. For flashable TPMs, can treat a TPM version change from 1.0 to 2.0 as a reinstall case, since migration would be very difficult.</p><p><br/></p><p><strong>ACTION: Ross and AIS Burlington to find out by January if they can sign up to perform QA for a March 7.0 release.</strong></p><h2>Tracking upstream Xen stable branch</h2><p>Christopher: Want to avoid maintaining an OpenXT-specific Xen build; use the upstream stable branch, which would currently be stable-4.6 for OpenXT master.</p><p>The branch contains XSA fixes plus important corrections. Is not high churn. Think that we could track the tip of that stable branch, since it doesn't appear that there is a minor release for every XSA fix issued. However, would also be fine with using minor releases if community and maintainers prefer that.</p><p>Suspect that if the XSA patches were removed, that the OpenXT patch queue would not break between Xen 4.6.1 and the tip of stable-4.6; should go and test that to obtain data to aid this decision.</p><p><br/></p><p>Eric: Preference for using the upstream minor release tarballs.</p><p>Easier for the build system mirror that using a git repository, and hoping that upstream perform testing on their minor releases.</p><p>Have been cases where upstream broke eg. XenStore in a stable branch, functionality that OpenXT depends upon.</p><p><br/></p><p>Rich: We need to detect that breakage and actively report it upstream.</p><p><br/></p><p>Ross: Also have a preference for the upstream minor release tarballs.</p><p><br/></p><p>Daniel: Still want to continue to see XSAs patched in OpenXT immediately when they exit embargo.</p><p><br/></p><p>Christopher: Well, that would be easiest using the upstream stable branch, and advancing along it to a specified commit, if there is no minor release issued.</p><p><br/></p><p><strong>ACTION: Christopher + Eric to work on a plan and PR.</strong></p><p><br/></p><h2>64-bit service VMs</h2><p>Daniel: network-slave is an obstacle: haskell, so needs to be a 32 bit binary.</p><p>Challenge is in getting a mixed 32-bit/64-bit build from standard OE build.</p><h2>Replace midori with surf browser</h2><p>Primary advocate for this not present on the call. No objections to the change expressed.</p><p>Discussed; test cycle for 7.0 release would be useful to validate a switch.</p><h2>meta-virtualization</h2><p>Christopher: meta-virtualization is an upstream OpenEmbedded layer with recipes for virtualization and container technologies and their dependencies,</p><p>eg. Docker, Go, lxc, KVM, libvirt, Xen, Linux.</p><p>Have a working prototype of OpenXT built with meta-virtualization layer; looks good, should be suitable for review in the New Year.</p><p>Rich: will enable collaboration with other users of virtualization in the wider, larger community in OpenEmbedded, which exceeds the size of the Xen community.</p><h2>Last call of the year</h2><p>Merry Winter Festivals to all!</p>",
    "date": "2024-11-15",
    "disclaimer": "Users of this benchmark dataset are advised to check Atlassianâ€™s official documentation for the most current information.",
    "space": "CS"
}